{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torch import optim\n",
    "import torch.nn as nn \n",
    "import timm\n",
    "from utils import get_indices, OPT, train_loop\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = torchvision.transforms.functional.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from continuum import InstanceIncremental\n",
    "from continuum.datasets import CIFAR100\n",
    "\n",
    "dataset = CIFAR100('~/data', transform=tt.ToTensor())\n",
    "scenario = InstanceIncremental(dataset, nb_tasks=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Number of classes: {scenario.nb_classes}.\")\n",
    "print(f\"Number of tasks: {scenario.nb_tasks}.\")\n",
    "\n",
    "for task_id, train_taskset in enumerate(scenario):\n",
    "    train_loader = DataLoader(train_taskset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for x, y, t in train_loader:\n",
    "        grid = make_grid(x[:16])\n",
    "        show(grid)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10.\n",
      "Number of tasks: 5.\n",
      "0\n",
      "tensor([0, 1]) 357 11424\n",
      "1\n",
      "tensor([2, 3]) 341 10912\n",
      "2\n",
      "tensor([4, 5]) 317 10144\n",
      "3\n",
      "tensor([6, 7]) 343 10976\n",
      "4\n",
      "tensor([8, 9]) 332 10624\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from continuum import ClassIncremental\n",
    "from continuum.datasets import MNIST\n",
    "from continuum.tasks import split_train_val\n",
    "\n",
    "\n",
    "\n",
    "dataset = MNIST(\"my/data/path\", download=True, train=True)\n",
    "scenario = ClassIncremental(\n",
    "    dataset,\n",
    "    increment=2,\n",
    "    initial_increment=2\n",
    ")\n",
    "\n",
    "print(f\"Number of classes: {scenario.nb_classes}.\")\n",
    "print(f\"Number of tasks: {scenario.nb_tasks}.\")\n",
    "\n",
    "for task_id, train_taskset in enumerate(scenario):\n",
    "    print(task_id)\n",
    "    train_taskset, val_taskset = split_train_val(train_taskset, val_split=0.1)\n",
    "    train_loader = DataLoader(train_taskset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_taskset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for x, y, t in train_loader:\n",
    "        # Do your cool stuff here\n",
    "        print(y.unique(), len(train_loader), len(train_loader)*32)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d80cef5c41f72c3aeaae0d0e38da3bf244997d0bc18ccf300b61a162cabda2ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
